---
title: "Codex CLI実践ガイド：ChatGPT Plus/Proで使える最新AIコーディングツールと実用技まとめ"
emoji: "🤖"
type: "tech"
topics: ["AI", "CodexCLI", "OpenAI", "開発効率化", "プロダクト開発"]
published: true
---

## はじめに

AI Empowersの平下です。ChatGPT Plus/Proで追加料金なしで使えるようになったCodex CLIについてまとめました。
ターミナルやVS CodeなどのIDE上で、自然言語を使って以下のような操作が可能になります。

- コード生成
- ファイル編集
- テスト実行
- Git操作
- Web検索
- MCPによる外部ツール連携

2025年4月に公開されたばかりですが、多くの開発者が使用しています。使用のためのTipsをひととおりまとめてみました。

## なぜ今、Codex CLIが注目されているのか？

### ChatGPTサブスクリプションで利用可能
GPT-5以降、ChatGPTの有料プラン (Plus/Pro/Team) 加入者は定額でCodex CLIを利用できるようになりました。当初はAPI Key前提でしたのでサブスクリプションで試せるのが大きいです

### Claude Codeの性能劣化問題
Xなどで「Claude Codeが以前より頭が悪くなった」「以前より性能が落ちた」という声が多く聞かれるようになり、Claude CodeからCodex CLIへの移行を検討する開発者が増えています。

## インストールと初期設定

### インストール

以下のコマンドでインストールします。

```bash
npm install -g @openai/codex
```

または

```bash
brew install codex
```


VS Code拡張機能も対応しています： 

https://developers.openai.com/codex/ide

起動は以下のコマンドです。

```bash
codex
```

## サインイン手順

> 1. Sign in with ChatGPT
>     Usage included with Plus, Pro, and Team plans
CodexのSignInはChatGPT accountの (Plus/Pro/Team)で実施してください。
成功すると `~/.codex/config.toml` にトークンが保存され、以降CLIが利用可能になります。

## 基本的な使い方

### 主要コマンド

| コマンド | Claude Code相当 | 説明 |
|---------|----------------|------|
| `/new` | `/clear` | 現在のセッションを破棄し、新しいセッションを開始 |
| `/compact` | `/compact` | 長くなった対話履歴をモデルに要約させ、トークンを節約 |

### ファイル操作

- `@/ファイル名`：ファイル名補完・明示的参照
- VS Code拡張では開いているファイルを自動参照
- 画像はShift + ドラッグやCtrl + Vで貼り付け可能

### 設定ファイルの構成

| ファイル名 | 設置場所 | 用途 |
|-----------|---------|------|
| AGENTS.md | ~/.codex/ | 全プロジェクトに共通の個人設定（グローバル・システムプロンプト） |
| config.toml | ~/.codex/ | Codex CLIの設定 |
| prompts/ | ~/.codex/prompts/ | カスタムプロンプト（スラッシュコマンド相当） |

### 日本語対応設定

`~/.codex/AGENTS.md` に以下を記述することで、デフォルトで日本語応答になります。

```markdown
日本語で簡潔かつ丁寧に回答してください
```

プロジェクト固有のルール（例：変数命名規則や言語設定）などを書くともっと便利になります。

### 初期セットアップ

設定ファイルは `~/.codex/config.toml` で管理します。以下は推奨設定例です。

```toml
model = "gpt-5-codex"                # デフォルトは GPT-5 Codex
preferred_auth_method = "chatgpt"    # APIキーではなく ChatGPT アカウントで認証
approval_policy = "on-request"       # 自動操作には都度承認を挟む
sandbox_mode = "workspace-write"

notify = ["bash", "-lc", "afplay /System/Library/Sounds/Ping.aiff"]

[tools]
web_search = true

[sandbox_workspace_write]
network_access = false               # デフォルトでは外部アクセス不可

model_reasoning_effort = "high"      # 通常は "medium" でバランス良し
model_verbosity = "low"              # 出力は冗長すぎない程度

# 任意: MCP サーバー連携が必要な場合のみ設定
[mcp_servers.brightData]
command = "npx"
args = ["-y", "@brightdata/mcp"]
env = { "API_TOKEN" = "YOUR_BRIGHTDATA_TOKEN", "PRO_MODE" = "true" }

show_raw_agent_reasoning = false
shell_environment_policy.experimental_use_profile = false
```

### 重要な設定

```toml
approval_policy = "on-request"
```
エージェントがファイルを書き換えたりコマンド実行したりする際、それを逐次確認できるようにします。誤操作・悪意のある動作を防ぐためのバランス型ポリシーです。

```toml
network_access = false
```
プロジェクトディレクトリ内での読み書き操作は許可しつつ、外部ネットワークアクセスはデフォルトではオフ。必要なときのみ設定を切り替えます。

```toml
preferred_auth_method = "chatgpt"
```
サブスクリプション（Plus/Pro/Team）利用ではcodex signinの認証トークンを使うので、APIキー認証は不要です。

```toml
notify = ["bash", "-lc", "afplay /System/Library/Sounds/Ping.aiff"]
```
タスク完了時などで通知音を鳴らします。notifyはmacOSの例です。他の環境ではPowerShell (windows) の通知コマンドに置き換えてください。

```toml
web_search = true
```
Webの最新の情報に基づいた回答を生成します。

```toml
model_reasoning_effort = "high"
```
デフォルトではmediumですが、highにすることで思考の精度が向上します。

```toml
[mcp_servers.brightData]
command = "npx"
args = ["-y", "@brightdata/mcp"]
env = { "API_TOKEN" = "YOUR_BRIGHTDATA_TOKEN", "PRO_MODE" = "true" }
```
Web検索、スクレイピング、外部ツール連携などを使いたいなら、MCPサーバーを構成しておくとよいです。

```toml
show_raw_agent_reasoning = false
```
通常はチェインオブソート（思考過程）の生出力を隠しておく方が見やすいですが、分析用途ではtrueにしてもよいです。


### カスタムプロンプト

頻繁に使うプロンプトを `~/.codex/prompts/` 配下にファイルとして保存し、スラッシュコマンドのように呼び出せます。

## セキュリティ考慮事項

### データの取り扱い

OpenAIは、ユーザーとの会話内容やアップロードされたファイルをモデルの学習には使用しないと明示しています。ただし以下の注意が必要です。

- APIやCLI経由で直接的に個人情報や社外秘を渡さない
- 入力する情報は抽象化・ボカすのが安心
- 機密性の高い処理は暗号化・匿名化で保護

### 自動実行を避けるべき例

以下のようなコマンドは慎重に実行することをオススメします。
これらはapproval_policyをon-requestにすることで安全に制御できる

- `npm install`（依存追加）
- `git commit`, `git push`
- `.env` ファイルの読み込み
- `rm`, `curl` などの危険性のあるコマンド

## プランと利用制限

| プラン             | 月額     | 使用可能モデル            | 想定用途       | 利用上限の目安*      |
| --------------- | ------ | ------------------ | ---------- | ------------- |
| Plus            | $20    | GPT-5, GPT-5-codex | 個人開発       | 30〜150通/5時間   |
| Pro             | $200   | GPT-5, GPT-5-codex | 高頻度利用・企業向け | 300〜1500通/5時間 |
| Team/Enterprise | 要問い合わせ | GPT-5, GPT-5-codex | 組織導入       | SLAに準拠        |


## 効果的な使い方のコツ

- Git操作：こまめに `git add` して変更管理を明確に
- `/new`：タスクが変わるごとに履歴をクリア
- `/compact`：履歴が膨らんできたら要約して軽量化
- reasoning effort "high"：思考の精度を最大化
- Web検索機能：最新の技術情報やライブラリ仕様を参照
- AGENTS.md：プロジェクトの思想や命名ルールを記述してAIのアシスト精度を向上
- MCPを活用してSlackやJira、Figmaなどの外部ツールとシームレスに連携


## 開発現場での実践例

開発リーダーやエンジニアがCodex CLIを活用する例としては以下があります。

- reasoning機能を使って構成案や仕様を深く検討させ、レビューを促進
- AGENTS.mdにプロジェクトの思想や命名ルールを記述し、AIのアシスト精度を向上
- Web検索機能を活用して最新のベストプラクティスや技術動向を踏まえた提案
- MCPを活用してFigmaやSlackなどの外部ツールとシームレスに連携
- カスタムプロンプトでよく使うリファクタリングや設計パターンを定型化

## 終わりに

Claude Codeが調子が悪いときや思うような出力がでないときに、Codex CLIを試してみる価値は十分にあります。
とくにGPT-5の高精度な推論機能とWeb検索機能は魅力的です。

- ChatGPT Plus/Proで追加料金なしで利用可能
- セットアップはシンプル、Claude Codeと同様の操作感
- Web検索機能で最新情報に対応
- reasoning機能で深い思考が可能
- MCPで外部ツールとの連携も強力

Claude Codeと併用して、プロダクトの立ち上げから実装まで、Codex CLIを使い倒しましょう！

## 参考サイト

- Codex CLI公式サイト  
  https://developers.openai.com/codex
- IDE連携（VS Codeなど）  
  https://developers.openai.com/codex/ide
- Codex CLIを使いこなすための機能・設定まとめ  
  https://zenn.dev/dely_jp/articles/codex-cli-matome
- 新Codex CLIの使い方  
  https://blog.lai.so/codex-rs-intro/
- MCP Remote  
  https://github.com/geelen/mcp-remote
- MCP Proxy  
  https://github.com/sparfenyuk/mcp-proxy